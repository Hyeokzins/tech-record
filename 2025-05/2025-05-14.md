# 2025-05-14 - 일일 기록

##  주요 업무 및 작업
- llm 강의자료 제작 localmcp 파트 추가
- 텍스트 박스 최적 배치 방법 구상(private)

##  배운 점 및 인사이트
- 로컬 mcp를 사용해야하는 이유에 대해 구글링을 진행하였을때 결과를 찾기 어려웠고
  대신 공개적인 mcp사용했을때 보안문제를 구글링하니 검색결과가 많이나와 보안관련문제등을 언급하며 진행하였음
  또한 겸사겸사 클로드 ai를 사용하였을때 클로드 체험판이 성능이 매우 좋은것을 알게됨
  코딩 애플님의 mcp 강의 영상을 보고 이해하고 참고하여 내가 이해한 대로 mcp 아키텍쳐를 그려보았다 (그래도 잘 모르겠다.)
  <img width="1438" alt="image" src="https://github.com/user-attachments/assets/bbc19a28-fc18-488a-97ff-57a9dd14bf86" />
  기업 재직자 대상 강의이니 로컬 mcp 강점을 설명 해보았다
  <img width="1311" alt="image" src="https://github.com/user-attachments/assets/6c0f606e-ae26-4dcd-bee7-29151526026a" />


##  로컬 환경에서 mcp 서버 구축 
### mcp_sever.py:
```python
from mcp.server.fastmcp import FastMCP
from sentence_transformers import SentenceTransformer
import fitz
import os

# LangChain 관련 추가
from langchain.chains import RetrievalQA
from langchain.llms import Ollama
from langchain.vectorstores import Chroma
from langchain.embeddings import SentenceTransformerEmbeddings

# MCP 서버
mcp = FastMCP(
    "DocumentQAServer",
    instructions="문서를 업로드하고, 질문하면 문서 기반 요약 응답을 제공합니다.",
    host="0.0.0.0",
    port=8005,
)

# 문서 임베딩 및 ChromaDB 설정
persist_dir = "./chroma_db"
os.makedirs(persist_dir, exist_ok=True)
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
embedding = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")
vectordb = Chroma(persist_directory=persist_dir, embedding_function=embedding)

# 문서 업로드 함수
def read_pdf_text(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        text += page.get_text()
    return text

@mcp.tool()
async def upload_document(file_path: str) -> str:
    if not os.path.exists(file_path):
        return f"[ERROR] 파일이 없습니다: {file_path}"

    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".pdf":
        text = read_pdf_text(file_path)
    elif ext in [".txt"]:
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
    else:
        return f"[ERROR] 지원하지 않는 파일 형식: {ext}"

    embedding_vector = embedding_model.encode([text])[0]
    vectordb.add_texts([text], embeddings=[embedding_vector.tolist()], ids=[os.path.basename(file_path)])
    
    return {"status": "문서 저장 완료"}

# LangChain QA 체인 설정
llm = Ollama(model="exaone3.5:7.8b")
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectordb.as_retriever(search_kwargs={"k": 3}),
    return_source_documents=False
)

# 문서 기반 질문 응답 함수
@mcp.tool()
async def ask_question(query: str) -> str:
    try:
        answer = qa_chain.run(query)
        return answer
    except Exception as e:
        return f"[ERROR] 질문 처리 중 오류 발생: {str(e)}"

# 서버 실행
if __name__ == "__main__":
    mcp.run(transport="sse")

```
서버에서 랭체인 툴을 만들고

### mcp_client.py:
```python
import asyncio
from langchain_mcp_adapters.client import MultiServerMCPClient
import json
import os

# MCP 도구 호출 함수
async def call_mcp_tool(client, tool_name, tool_args):
    tools = client.get_tools()
    tool = next((t for t in tools if t.name == tool_name), None)
    if tool is None:
        raise ValueError(f"Tool '{tool_name}' not found")
    return await tool.coroutine(**tool_args)

# 문서 업로드 함수
async def upload_document(client, file_path):
    result = await call_mcp_tool(client, "upload_document", {"file_path": file_path})
    parsed_result = json.loads(result[0])
    print("[문서 업로드 결과]", parsed_result)

# 질문하기 (문서 기반 QA)
async def ask_question(client, query):
    ask_result = await call_mcp_tool(client, "ask_question", {"query": query})
    #ask_result = ask_result.replace('\n\n', '\n')
    print("[문서 기반 응답 결과]", ask_result)

# 메인 실행
async def main():
    async with MultiServerMCPClient(
        {
            "qa": {
                "url": "http://localhost:8005/sse",
                "transport": "sse",
            }
        }
    ) as client:
        pdf_path = os.path.abspath("../news_weather.pdf")
        await upload_document(client, pdf_path)
        await ask_question(client, "집중 호우의 원인은 무엇인가요?")
        


try:
    asyncio.get_event_loop().run_until_complete(main())
except RuntimeError:  
    asyncio.ensure_future(main())

```
클라이언트를 이용해 도구를 꺼내고 활용해보았다
다만 에이전트로 도구사용은 하지않았고 내가 직접 도구호출을 하였다

##  내일 할 일
- 텍스트 박스 최적 배치 방법 구상 및 두산 라벨링 진행
