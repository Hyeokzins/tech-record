# 2025-11-20 - 일일 기록

## 주요 업무 및 작업

### ISBI 2015 Cephalometric 랜드마크 탐지 예제 실습
- Landmarker 패키지를 사용한 2D 의료 영상 랜드마크 탐지 학습 진행
- 데이터셋: ISBI 2015 (400개 두개골 X-ray, 19개 랜드마크)
  - 학습: 150개, 테스트1: 150개, 테스트2: 100개

### 데이터 준비 과정
- RAR 압축 해제 문제 발생
  - `landmarker` 자동 다운로드 중 `rarfile` 라이브러리 에러
  - WinRAR 설치 후 `AnnotationsByMD.rar`, `RawImage.rar` 수동 압축 해제
- 데이터 증강: 회전, 이동, 스케일, 노이즈 등 랜덤 변형 적용

### 학습 속도 최적화 과정

#### 1단계: 초기 상태 (CPU 사용)
- **문제**: 1 에폭당 3~4분 소요 → 200 에폭 시 약 20시간 예상
- **원인 파악**: PyTorch가 CPU로 실행 중
```python
  print(torch.cuda.is_available())  # False
  print(torch.__version__)  # 2.9.1+cpu
```
- 동일 가상환경에서 MONAI 추론도 느렸던 이유 발견

#### 2단계: GPU 활성화
- **해결**: CUDA 버전 PyTorch 재설치
```bash
  pip uninstall torch torchvision torchaudio -y
  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```
- **결과**: 20시간 → 12시간으로 단축 (40% 개선)

#### 3단계: 배치 크기 최적화 시도
- **초기 설정**: `batch_size = 1` (예제 기본값)
- **시도**: 배치 크기를 32 → 16 → 8로 조정
  - GPU 메모리 부족으로 8 이하로 제한
  - 고성능 컴퓨터(RTX 6000 Ada 48GB×3)로 이전 후 재시도
- **결과**: 배치 크기 증가해도 속도 개선 미미

#### 4단계: 병목 구간 분석
- **관찰**: 
  - 학습 중: GPU 활발히 사용 (17~24%)
  - 에폭 전환 시: GPU/CPU 유휴 상태
- **결론**: 데이터 로딩이 병목 구간
  - GPU 학습 자체는 매우 빠름 (배치당 0.23초)
  - 데이터 준비 시간이 전체 시간의 대부분 차지
  - GPU가 데이터를 기다리며 유휴 상태

#### 5단계: DataLoader 최적화 (최종)
```python
train_loader = DataLoader(
    ds_train, 
    batch_size=batch_size, 
    shuffle=True, 
    num_workers=4,              # CPU 코어 활용
    pin_memory=True,            # GPU 전송 속도 향상
    persistent_workers=True,    # 에폭 간 워커 재사용
    prefetch_factor=2           # 다음 배치 미리 준비
)
```

---

## 배운 점 및 인사이트

### 1. PyTorch GPU 설정의 중요성
- **교훈**: 가상환경에 PyTorch CPU 버전이 설치되어 있으면 GPU가 있어도 사용 안 됨
- **확인 방법**:
```python
  import torch
  print(f"CUDA 사용 가능: {torch.cuda.is_available()}")
  print(f"PyTorch 버전: {torch.__version__}")  # +cu118, +cu121 등 확인
```
- 이전 MONAI 작업도 CPU로 진행했던 것을 뒤늦게 발견

### 2. 배치 크기 ≠ 속도의 해답
- **통념**: 배치 크기를 크게 하면 학습이 빨라진다
- **실제**: GPU 연산이 병목이 아니면 효과 미미
- 배치 크기 1 → 16으로 증가해도 시간 단축 거의 없음
- **이유**: 데이터 로딩 시간이 GPU 연산 시간보다 훨씬 김

### 3. 병목 구간 정확한 진단의 중요성
- 작업 관리자로 GPU/CPU 사용률 모니터링
- 학습 중 vs 에폭 전환 시 리소스 사용 패턴 비교
- **발견**: GPU는 빠른데 데이터 로딩이 느림

### 4. DataLoader 최적화 기법
- **`num_workers`**: CPU 멀티프로세싱으로 데이터 로딩 병렬화
- **`pin_memory`**: GPU 메모리로 직접 전송 (복사 단계 생략)
- **`persistent_workers`**: 워커 프로세스 재사용 (생성/종료 오버헤드 제거)
- **`prefetch_factor`**: 다음 배치 미리 준비 (GPU 대기 시간 최소화)

### 5. 예제 코드의 함정
- 예제는 "작동 여부"에 초점 (안정성 우선)
- 실제 사용 시 환경에 맞는 최적화 필수
- `batch_size = 1`은 안전한 기본값일 뿐, 최적값이 아님

---

## 문제 해결 및 코드 예시

### 문제 1: 데이터 로딩 병목

**최적화 전**:
```python
train_loader = DataLoader(
    ds_train,
    batch_size=1,
    shuffle=True,
    num_workers=0  # 단일 프로세스
)
# 결과: 1 에폭 3~4분
```

**최적화 후**:
```python
train_loader = DataLoader(
    ds_train,
    batch_size=16,              # GPU 메모리 허용 범위 내 최대
    shuffle=True,
    num_workers=4,              # CPU 코어 활용 (코어 수의 절반~전체)
    pin_memory=True,            # GPU 직접 메모리 전송
    persistent_workers=True,    # 워커 재사용 (에폭 간 생성/삭제 제거)
    prefetch_factor=2           # 2개 배치 미리 준비
)

val_loader = DataLoader(
    ds_test1,
    batch_size=16,
    shuffle=False,
    num_workers=4,
    pin_memory=True,
    persistent_workers=True,
    prefetch_factor=2
)

test_loader = DataLoader(
    ds_test2,
    batch_size=16,
    shuffle=False,
    num_workers=4,
    pin_memory=True,
    persistent_workers=True,
    prefetch_factor=2
)
```

**성능 개선 결과**:
- 초기 (CPU): 1 에폭 3~4분 → 200 에폭 약 20시간
- GPU 적용: 1 에폭 약 2분 → 200 에폭 약 12시간 (40% 단축)
- DataLoader 최적화: 추가 개선 (구체적 수치는 측정 중)

---

### 문제 3: 환경 복제 (다른 컴퓨터에 동일 환경 구축)

**최소 환경 설정 파일** (`environment.yml`):
```yaml
name: medsam2
channels:
  - conda-forge
dependencies:
  - python=3.12
  - pip
  - pip:
      # 핵심 패키지
      - monai==1.5.1
      - landmarker==0.4.0
      - nibabel==5.3.2
      
      # 데이터 처리
      - numpy
      - pandas
      - scipy
      
      # 이미지 처리
      - scikit-image
      - opencv-python
      - pillow
      
      # 시각화
      - matplotlib
      - seaborn
      
      # 주피터
      - jupyter
      - jupyterlab
      - ipykernel
      
      # 유틸리티
      - tqdm
      - pyyaml
      - rarfile
```

**설치 순서**:
```bash
# 1. 환경 생성
conda env create -f environment.yml

# 2. PyTorch 별도 설치 (CUDA 버전에 맞게)
conda activate medsam2
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 3. 주피터 커널 등록
python -m ipykernel install --user --name medsam2 --display-name "medsam2"
```

---



## 추가 인사이트

### GPU 사용률이 낮은 이유
- GPU 사용률 17~24%로 낮았던 이유:
  1. 배치 크기가 작음 (GPU 연산량 부족)
  2. 데이터 로딩이 느려서 GPU가 대기
  3. 이미지 크기가 작음 (512×512)
  
- 배치 크기를 늘려도 속도가 안 오른 이유:
  - GPU 연산이 아닌 데이터 로딩이 병목
  - GPU는 이미 충분히 빠름 (놀고 있음)

### 성능 컴퓨터 비교
- **원래 컴퓨터**: RTX 3080 Ti 12GB
- **옮긴 컴퓨터**: RTX 6000 Ada Generation 48GB × 3개
- 더 좋은 GPU로 옮겨도 속도 개선 없음 → 데이터 로딩이 병목임을 확인


##  내일 할 일
- ppt 자료준비
