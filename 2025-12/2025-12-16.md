# 2025-12-16 - 일일 기록

##  주요 업무 및 작업
- 머신러닝 시험 공부
- 심장 세그멘테이션 방법론 조사
- 심방,심실 까지 세그멘트 하는방법 과 분류결과를 예시로 제공해주었고 이것을 참고해서 심실,심방 분류 결과를 보내주면 병원측에서 검토해주겠다라는 것을 요청사항을 이해하는데 좀 시간이 걸림
- 심장부위 전문 세그멘트 모델은 현재 모나이에서는 없는것 같음 상체 부위 에서 심장 이 곁다리로 있음 이러면 문제점이 상체에는 100가지 섹션이 나뉘는데 심장은 4가지 섹션밖에없음 한마디로 낭비임
- 심장 전용모델을 찾는것을 해보고 예시그림 따라서 만들어보자 그리고 이와별개로 전체 세그멘트에서 심장만 추출한 결과도 비교해보자


##  머신러닝 공부 내용 
머신러닝 및 응용

1.지도학습과 비지도학습의 차이를 구체적인 예시를 들어 설명하시오.
- 지도학습은 입력(문제)과 대응하는 출력(답)을 데이터로 제공하고 대응관계의 함수 또는 패턴을 찾는것
예시로는 분류문제(필기체인식,스팸메일분류) 또는 회귀 문제(주가 예측)가 있음
- 비지도학습은 데이터만 주어진 상태에서 유사한것들을 서로 묶어 군집을 찾거나 답이 없는 문제들만 있는 데이터들로부터 패턴을 추출하는것 예시는 군집화가있음
- 비지도학습 구체화 군집화:유사한 샘플을 모아 같은 그룹으로 묶는일(맞춤광고,실시간검색어 키워드), 밀도추정(분류,생성모델 구축):데이터로부터 확률분포를 추정하는일,공간변환(데이터 가시화,특징추출):원래특징공간을 저차원 또는 고차원 공간으로 변환하는일
- 조사한 답변:
  - 지도학습: 레이블(정답)이 있는 데이터로 학습하여 입력과 출력 간의 관계를 학습합니다. 새로운 입력에 대해 출력을 예측하는 것이 목표입니다. 분류(이미지 분류, 스팸 필터링)와 회귀(집값 예측, 주가 예측) 문제에 사용됩니다.
  - 비지도학습: 레이블이 없는 데이터에서 숨겨진 구조나 패턴을 발견합니다. 군집화(고객 세분화, 문서 그룹화), 차원 축소(PCA를 통한 데이터 시각화), 이상치 탐지(네트워크 침입 탐지) 등에 사용됩니다.


2.훈련 데이터에 과적합(Overfitting)이 발생하는 이유를 설명하고, 이를 완화하기 위한 대표적인 방법 3가지(규제 포함)를 제시하시오.
- 내답변: 훈련데이터의 개수가 적거나 또는 다양성이 부족해서 해당 데이터 만으로 학습해서 발생한다
 이를 완화하기위해서는 규제를 먹여 학습률 건든다, 데이터 분포 다양화한다,
- 자료를기반한 답변:모델의 용량이크다(?) 그래서 학습 과정에서 잡음까지 수용해서 과적합발생
 이를 완화하기 위해서는 특성 선택을한다(p개의 변수들중 가장좋은 k개를 선택)
 규제를 통해 모델의 복잡도를 제한한다(모델의 파라미터 값의 크기를 제한)
 데이터의 차원을줄임 핵심이 되는 파라미터만을 선별해워 문제의 차원을 낮춰야함
 (데이터 차원이 증가할수록 해당공간의 크기가 기하급수적으로 증가함,강의자료3-1 17)
- 조사한 답변:
  - 발생 이유: 모델이 너무 복잡하거나(파라미터가 많음), 훈련 데이터가 부족하거나, 노이즈가 많을 때 발생합니다. 모델이 훈련 데이터의 노이즈까지 학습하여 일반화 성능이 떨어집니다.
  - 완화 방법 3가지:
    1. 규제(Regularization): L1(Lasso), L2(Ridge) 규제를 통해 파라미터 크기를 제한하여 모델 복잡도를 줄입니다.
    2. 데이터 증강(Data Augmentation): 훈련 데이터를 회전, 확대, 노이즈 추가 등으로 다양화하여 데이터 양을 늘립니다.
    3. 조기 종료(Early Stopping): 검증 손실이 증가하기 시작하면 학습을 중단하여 과적합을 방지합니다.


3.모델의 일반화 성능을 평가하기 위해 교차검증(Cross-validation)을 사용하는 이유를 설명하시오.
- 테스트에 사용하는 데이터를 제외한 나머지데이터를 모두 골고루 학습과 검증에 사용해야하기 때문
학습데이터로 한정해놓으면 검증데이터를 학습을 못할수도있어서?
- 자료기반 답변:훈련세트와검증세트를 여러개로 쪼갠후 그것을 돌아가면서 모두 학습과 검증에 이용할수있기때문
- 조사한 답변:
  - 단순 분할의 문제: 데이터를 한 번만 훈련/검증 세트로 나누면 특정 분할에 따라 성능이 크게 달라질 수 있고, 검증 세트가 대표성이 없을 수 있습니다.
  - 교차검증의 장점: 데이터를 K개 fold로 나누고 각 fold를 순서대로 검증 세트로 사용하며 나머지로 학습합니다. 모든 데이터가 학습과 검증에 사용되므로 더 신뢰할 수 있는 성능 평가가 가능하고, 데이터 분할에 따른 편향을 줄입니다.
  - K-fold 교차검증: K번의 학습/평가를 수행하여 평균 성능을 계산하므로 안정적이고 일반화된 성능 추정이 가능합니다.


4.차원축소 (PCA)를 사용하는 목적과 커널 PCA를 사용 시 어떤 효과를 얻게 되는지 설명하시오. (5장)
- 내 답변:복잡해지지않는다..?
- 자료기반 답변
  - 차원축소의 목적은 차원이 증가할수록 데이터포인트간의 거리가 증가하므로 이런 구조로 학습하면 모델이 복잡해지며 오버피팅됨 그래서 고차원 데이터를 저차원으로 데이터 변환을 하는것이 필요
  - 그중 PCA(주성분분석) 데이터를 가장 잘설명할수있는 초평면을 구하고 그곳에 데이터를 투영시켜 차원을 줄이는것 2차원으로 줄일수있음
  - 단점은 비선형적 패턴에는 적용하기 어려움
  - 비선형적 문제는 커널 PCA를 이용
- 조사한 답변:
  - PCA 목적: 고차원 데이터의 분산을 최대한 보존하면서 저차원으로 투영합니다. 차원의 저주(curse of dimensionality) 완화, 계산 비용 감소, 시각화 가능, 노이즈 제거, 과적합 방지 효과가 있습니다.
  - PCA 방법: 데이터의 공분산 행렬에서 고유값이 큰 주성분(principal component)을 찾아 그 방향으로 데이터를 투영합니다.
  - 커널 PCA 효과: 일반 PCA는 선형 변환만 가능하지만, 커널 트릭을 사용하여 데이터를 고차원 공간으로 매핑한 후 PCA를 수행합니다. 따라서 비선형 패턴도 효과적으로 차원 축소할 수 있습니다. (예: 동심원 형태 데이터 분리)


5.SVM(서포트 벡터 머신)에서 '마진'을 최대화한다는 의미를 기하학적으로 설명하시오. (4장)
- 내답변 직선w에서 떨어진너비 를 마진이라고함 이것을 크게하면 직선에서 떨어진너비가 넓어짐 마진안에 샘플이 들어오지않는데 이를 넓게한다는건 최대한 두샘플을 과 가장 멀리떨어져있으면서도 분리를 잘할수있는 것? (최대마진의 의미인듯이건 최대화한다는의미를 기하학으로 설명하는건 앞단에 설명)
- 자료답변 모든 샘플을 옳게 분류하는조건하에 최대마진을 갖는 초평면을찾는다?
- 조사한 답변:
  - 마진의 정의: 결정 경계(초평면)와 가장 가까운 훈련 샘플(서포트 벡터) 사이의 거리입니다. 양쪽 클래스에서 가장 가까운 점들 사이의 폭을 의미합니다.
  - 마진 최대화의 의미: 두 클래스를 분리하는 초평면을 그을 때, 양쪽 클래스의 가장 가까운 점들로부터 최대한 멀리 떨어진 초평면을 찾는 것입니다. 기하학적으로는 결정 경계의 "안전 영역"을 최대한 넓게 만드는 것입니다.
  - 장점: 마진이 클수록 일반화 성능이 좋아지고, 새로운 데이터에 대해 더 안정적인 분류가 가능합니다. 노이즈나 이상치에 덜 민감해집니다.


6.정확률(Accuracy) 대신 Precision, Recall, F1-score를 사용해야 하는 상황을 예시와 함께 설명하시오.
- precision(정밀도,예상정답이 진짜 정답인것): 스팸메일 예측,금융사기예측 스팸아닌데 스팸으로 처리하면 큰일
- recall(재현율,예상음성이 진짜 음성인것):암환자 예측 암환자를 정상으로 판정하면 큰일 +불량품검사
- f1스코어 사용상황 둘다 중요할때 예시 추천시스템 정밀도를 높이려고 추천후보군을 5개만올림 -> 추천이 별로안뜸 정확도는 높지만 그렇다고 추천 100개올림 이러면 선택지는많은데 별로인선택지가 더많아짐 이를 적절하게 20개 추천하면 개수가적당히 있으면서 별로인것도 적당히 즉 극단적인 리스크 없는상황에서 시도?
- 조사한 답변:
  - Accuracy의 한계: 클래스 불균형 상황에서 모든 샘플을 다수 클래스로 예측해도 높은 정확도가 나올 수 있음 (예: 암환자 5%, 정상 95%인 데이터에서 모두 정상으로 예측하면 Accuracy 95%지만 암환자를 전혀 못 찾음)
  - Precision이 중요한 상황: FP(False Positive)를 최소화해야 할 때. 스팸메일 필터(중요 메일을 스팸으로 분류하면 큰 손실), 금융사기 탐지(정상 거래를 사기로 판정하면 고객 불편)
  - Recall이 중요한 상황: FN(False Negative)을 최소화해야 할 때. 암 환자 진단(암 환자를 정상으로 판정하면 치료 시기 놓침), 불량품 검사(불량품을 정상으로 판정하면 시장 출고), 침입 탐지 시스템(해킹 시도를 놓치면 보안 침해)
  - F1-score가 중요한 상황: Precision과 Recall의 균형이 필요할 때. 추천 시스템(추천한 상품이 관심 있는 것이어야 하면서도 관심 있는 상품을 최대한 추천해야 함), 클래스 불균형 데이터셋


7.앙상블 학습(Ensemble Learning)이 단일 모델보다 좋은 성능을 내는 이유를 배깅(Bagging), 부스팅(Boosting)을 비교하며 설명하시오.
- 조사한 답변:
  - Bagging (Bootstrap Aggregating): 원본 데이터에서 중복 허용 샘플링으로 여러 데이터셋을 만들고, 각 데이터셋으로 독립적인 모델을 병렬 학습한 후 예측을 평균하거나 투표합니다. 각 모델이 서로 다른 데이터로 학습하므로 다른 오류를 발생시키고, 이를 평균 내면 오류가 상쇄되어 분산(Variance)이 감소합니다. 따라서 과적합이 방지되고 예측이 안정적입니다. 대표 알고리즘은 Random Forest입니다.
  - Boosting: 첫 번째 약한 모델을 학습한 후, 틀린 샘플에 가중치를 부여하여 다음 모델이 이전 모델의 오류(잔차)에 집중하도록 순차적으로 학습합니다. 약한 모델들을 가중합으로 결합하면, 각 모델이 이전 모델의 약점을 반복적으로 보완하여 편향(Bias)이 감소합니다. 따라서 단순한 약한 모델들이 합쳐져 복잡한 패턴을 학습하고 높은 정확도를 달성합니다. 대표 알고리즘은 XGBoost, LightGBM, AdaBoost입니다.
  - 비교 및 결론: Bagging은 병렬 학습으로 분산을 감소시켜 과적합을 방지하고, Boosting은 순차 학습으로 편향을 감소시켜 정확도를 향상시킵니다. 단일 모델은 편향-분산 트레이드오프로 인해 둘 중 하나를 개선하면 다른 하나가 악화되지만, 앙상블 학습은 여러 모델을 결합하여 이 한계를 극복하므로 단일 모델보다 우수한 성능을 냅니다.

##  내일 할일
- 심방 심실 세그멘트 방법론 구체화 
- 3D 랜드마크 방식 수치 수정
- PDF 텍스트변경,색상변경
- progressive 방식 이미지 전처리 과정 최적화
- 논문 리뷰 성능 분석 위주 + 이전 연구실내 연구에서 256-512 보간 왜했는지 분석
